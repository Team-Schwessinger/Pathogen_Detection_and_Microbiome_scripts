{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to pull down all the information for figure 5, and figure S2 - S5 (ncbi hits). The design is to compair between each sample (barcode) instead of each flowcell as they sequenced the same thing. Therefore I just pulled all the ncbi hits for each flowcell for each barcode and merged them together according to the barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from itertools import product\n",
    "import argparse\n",
    "from ete3 import NCBITaxa \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All information are in the BASEDIR for each replicate. Here again used replicate4 as an example\n",
    "BASEDIR = '/home/yiheng/data/20170617_replicate4'\n",
    "\n",
    "# here we define the folder name of the dataframe it created by capturing the folder from the BASDIR\n",
    "folder_name = os.path.basename(BASEDIR)\n",
    "column_name = folder_name.split('_')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first check if the analysis folder is there\n",
    "folder_list = 'analysis  basecalled_data  scripts  tracking  workspace'.split(' ')\n",
    "for x in range(0,folder_list.count('')):\n",
    "    folder_list.remove('')\n",
    "\n",
    "if not set(os.listdir(os.path.abspath(BASEDIR))) == set (folder_list):\n",
    "    print(\"Something wrong with basefolder. check it please.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiheng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# get the dataframe there\n",
    "dataframe = os.path.join(BASEDIR, 'analysis', 'summary_df_%s.tab' % folder_name)\n",
    "sum_df = pd.read_csv(dataframe, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['read_id', 'passes_filtering', 'sequence_length_template',\n",
       "       'mean_qscore_template', 'barcode_arrangement', 'barcode_score', 'kit',\n",
       "       'variant', 'pc_survived', 'nl_survived', 'qseqid_rg', 'sseqid_rg',\n",
       "       'evalue_rg', 'length_rg', 'pident_rg', 'nident_rg', 'sacc_rg',\n",
       "       'staxids_rg', 'scomnames_rg', 'read_length_pc_x', 'qseqid_nt',\n",
       "       'sseqid_nt', 'evalue_nt', 'length_nt', 'pident_nt', 'nident_nt',\n",
       "       'sacc_nt', 'staxids_nt', 'scomnames_nt', 'read_length_pc_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fills the nan with T/F for easier handling\n",
    "sum_df.sseqid_rg.fillna(False, inplace=True)\n",
    "sum_df.sseqid_nt.fillna(False, inplace=True)\n",
    "# filter out the rg blast hit\n",
    "total_reads = sum_df[((sum_df.sseqid_rg != False) | (sum_df.sseqid_nt != False)) & (sum_df.passes_filtering == True) & (sum_df.pc_survived == True) & (sum_df.nl_survived == True)]\n",
    "ntblasthit_reads = total_reads[(total_reads.sseqid_rg == False) & (total_reads.sseqid_nt != False)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Removing unncessary columns from joint_NCBI_df_taxonomy\n",
    "#I hard coded to select as it depends on what information you need\n",
    "for columns in ['passes_filtering',\n",
    "       'mean_qscore_template', 'barcode_score', 'kit',\n",
    "       'variant', 'pc_survived', 'nl_survived', 'qseqid_rg', \n",
    "       'evalue_rg', 'length_rg', 'pident_rg', 'nident_rg', 'sacc_rg',\n",
    "       'staxids_rg', 'scomnames_rg', 'read_length_pc_x', 'qseqid_nt',\n",
    "       'sseqid_nt', 'evalue_nt', 'length_nt', 'pident_nt', 'nident_nt',\n",
    "       'sacc_nt','scomnames_nt', 'read_length_pc_y']:\n",
    "    del total_reads[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/yiheng/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py:3643: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "###########This block for barcodes order\n",
    "# now everything left is what we want to plot out\n",
    "# arrange different barcodes\n",
    "# REMEMBER: This need to be manual check:\n",
    "# barcode01 is Pst infected sample, barcode02 is Zymo sample, 03 is nill sample, 04 is co-infection sample and 05 is Pyre sample\n",
    "new_barcodes = ['barcode01', 'barcode02', 'barcode03', 'barcode04', 'barcode05']\n",
    "if column_name == 'replicate1':\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode01')], inplace = True)\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode02', value='barcode01')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode06', value='barcode02')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode04', value='barcode06')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode05', value='barcode04')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode06', value='barcode05')\n",
    "\n",
    "elif column_name == 'replicate2':\n",
    "    # first delete the rows that contains the barcode we are going to replace\n",
    "    # I think maybe better to first adjust the df to get rid of all the mis/unclassified reads so the df get smaller\n",
    "    # and we do not need those reads for plotting\n",
    "    \n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode01')], inplace = True)\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode02')], inplace = True)\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode03')], inplace = True)\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode04')], inplace = True)\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode05')], inplace = True)\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('unclassified')], inplace = True)\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode07', value='barcode01')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode08', value='barcode02')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode09', value='barcode05')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode10', value='barcode04')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode11', value='barcode03')\n",
    "    \n",
    "elif column_name == 'replicate3':\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode06')], inplace = True)\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode03', value='barcode06')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode05', value='barcode03')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode06', value='barcode05')\n",
    "\n",
    "elif column_name == 'replicate4':\n",
    "    total_reads.drop(total_reads.index[total_reads.barcode_arrangement.str.contains('barcode06')], inplace = True)\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode03', value='barcode06')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode05', value='barcode03')\n",
    "    total_reads.barcode_arrangement = total_reads.barcode_arrangement.replace(to_replace='barcode06', value='barcode05')\n",
    "else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now just filter out all the reads that are not going to used for ploting\n",
    "barcode01_total = total_reads[total_reads.barcode_arrangement.str.contains('barcode01')]\n",
    "barcode02_total = total_reads[total_reads.barcode_arrangement.str.contains('barcode02')]\n",
    "barcode03_total = total_reads[total_reads.barcode_arrangement.str.contains('barcode03')]\n",
    "barcode04_total = total_reads[total_reads.barcode_arrangement.str.contains('barcode04')]\n",
    "barcode05_total = total_reads[total_reads.barcode_arrangement.str.contains('barcode05')]\n",
    "\n",
    "# now concat them together. but remember that the index has to change to add the column for ncbi taxa\n",
    "total_reads_filtered_barcodes = pd.concat([barcode01_total, \n",
    "                                           barcode02_total, \n",
    "                                           barcode03_total, \n",
    "                                           barcode04_total, \n",
    "                                           barcode05_total], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reads_filtered_barcodes.staxids_nt.fillna(False, inplace=True)\n",
    "ntblasthit_reads_filtered_barcodes = total_reads_filtered_barcodes[(total_reads_filtered_barcodes.staxids_nt != False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntblasthit_reads_filtered_barcodes = ntblasthit_reads_filtered_barcodes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as the concate before will result the staxid into a string\n",
    "# so now change the string back to float so it can be recognized by the NCBITaxa\n",
    "for taxid in ntblasthit_reads_filtered_barcodes['staxids_nt']:\n",
    "    if ';' in str(taxid):\n",
    "        taxid = taxid.split(';')[0]\n",
    "    else:\n",
    "        pass\n",
    "    float(taxid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to generate taxonomy columns based on NCBITaxa results for NCBI hit dataframe, \n",
    "def search_rank_output_name_append_column(df, staxid_column, rank_search):\n",
    "    \"\"\"Input df, staxid_column from same df and rank_search (a desired taxonomic rank \n",
    "    from each staxid's lineage), outputs taxonomic name corresponding to rank_search or 'Unclassified' if\n",
    "    unavailable and appends to df row by row\"\"\"\n",
    "    rank_list = []\n",
    "    for read_index in range(0, len(staxid_column)):\n",
    "        taxid = ''\n",
    "        if ';' in str(staxid_column[read_index]):\n",
    "            taxid = staxid_column[read_index].split(';')[0]\n",
    "        else:\n",
    "            taxid = staxid_column[read_index]\n",
    "        \n",
    "        taxid_lineage = ''\n",
    "        taxid_lineage = ncbi.get_lineage(taxid)\n",
    "        \n",
    "        names = ''\n",
    "        names = ncbi.get_taxid_translator(taxid_lineage)\n",
    "        \n",
    "        ranks = ''\n",
    "        ranks = ncbi.get_rank(taxid_lineage) #Dict\n",
    "        \n",
    "        ranks2names = ''\n",
    "        ranks2names = {ranks[k]:names[k] for k in names.keys() & ranks}\n",
    "        \n",
    "        if rank_search in ranks2names.keys():\n",
    "            rank_list.append(ranks2names[rank_search])#if rank in dict, print name\n",
    "        else:\n",
    "            rank_list.append('Unclassified')\n",
    "    df[rank_search] = rank_list\n",
    "# NOTE: Appending is always slow, try and find a better way e.g df.apply to a column based on staxids column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ntblasthit_reads_filtered_barcodes_added_TaxaRank = ntblasthit_reads_filtered_barcodes.copy()\n",
    "rank_list = ['superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "for rank in rank_list:\n",
    "    search_rank_output_name_append_column(ntblasthit_reads_filtered_barcodes, \n",
    "                                          ntblasthit_reads_filtered_barcodes.staxids_nt, \n",
    "                                          rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the flowcell column just in case\n",
    "ntblasthit_reads_filtered_barcodes = ntblasthit_reads_filtered_barcodes.assign(Flowcell = column_name)\n",
    "total_reads_filtered_barcodes = total_reads_filtered_barcodes.assign(Flowcell = column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_reads_filtered_barcodes.to_csv(r'/home/yiheng/analysis/WGS/%s_totaltaxa.tab' % column_name, header=column_name, index=None, sep='\\t')\n",
    "ntblasthit_reads_filtered_barcodes.to_csv(r'/home/yiheng/analysis/WGS/%s_nttaxa.tab' % column_name, header=column_name, index=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
